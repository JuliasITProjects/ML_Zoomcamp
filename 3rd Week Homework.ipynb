{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c90dac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: Most frequent observation for transmission_type: AUTOMATIC\n",
      "Question 2: The two features with the biggest correlation are: city mpg and highway MPG\n",
      "Question 3: Variable with the lowest mutual information score: Make_Alfa Romeo\n",
      "Question 4: Accuracy on the validation dataset: 0.93\n",
      "Question 5: Feature with the smallest difference: Make\n",
      "Question 6: Best alpha for Ridge regression: 0.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import Ridge\n",
    "from math import sqrt\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "data = pd.read_csv(\"D:\\Machine Learning Zoomcamp\\Week3-Homework\\data.csv\")\n",
    "\n",
    "# Select the desired features and perform data preparation\n",
    "selected_features = [\n",
    "    'Make',\n",
    "    'Model',\n",
    "    'Year',\n",
    "    'Engine HP',\n",
    "    'Engine Cylinders',\n",
    "    'Transmission Type',\n",
    "    'Vehicle Style',\n",
    "    'highway MPG',\n",
    "    'city mpg',\n",
    "    'MSRP'\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    'Year',\n",
    "    'Engine HP',\n",
    "    'Engine Cylinders',\n",
    "    'highway MPG',\n",
    "    'city mpg',\n",
    "    'price'\n",
    "]\n",
    "\n",
    "data = data[selected_features].copy()\n",
    "\n",
    "data.fillna(0, inplace=True)\n",
    "data.rename(columns={'MSRP': 'price'}, inplace=True)\n",
    "\n",
    "# Question 1: Most frequent observation (mode) for transmission_type\n",
    "mode_transmission_type = data['Transmission Type'].mode()[0]\n",
    "print(\"Question 1: Most frequent observation for transmission_type:\", mode_transmission_type)\n",
    "\n",
    "# Question 2: Correlation between numerical features\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = data[numerical_features].corr()\n",
    "\n",
    "\n",
    "# Find the two features with the biggest correlations (excluding self-correlation)\n",
    "max_corr_pairs = correlation_matrix.unstack().sort_values(ascending=False)\n",
    "max_corr_pairs = max_corr_pairs[max_corr_pairs < 1.0]  # Exclude self-correlation\n",
    "\n",
    "# Get the feature names with the biggest correlations\n",
    "(feature1, feature2), correlation_value = max_corr_pairs.index[0], max_corr_pairs.iloc[0]\n",
    "\n",
    "print(\"Question 2: The two features with the biggest correlation are:\", feature1, \"and\", feature2)\n",
    "\n",
    "\n",
    "# Question 3: Mutual information scores for categorical variables\n",
    "X = data.drop(columns=['price'])\n",
    "y = (data['price'] > data['price'].mean()).astype(int)\n",
    "\n",
    "categorical_features = ['Make', 'Model', 'Transmission Type', 'Vehicle Style']\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_encoded = encoder.fit_transform(X[categorical_features])\n",
    "\n",
    "# Calculate the mutual information scores for categorical variables\n",
    "mi_scores = mutual_info_classif(X_encoded, y, discrete_features='auto', random_state=42)\n",
    "\n",
    "# Get the feature names for one-hot encoded variables\n",
    "encoded_feature_names = encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "mi_scores_df = pd.DataFrame({'Feature': encoded_feature_names, 'Mutual_Info_Score': mi_scores})\n",
    "\n",
    "# Find the variable with the lowest mutual information score\n",
    "lowest_mi_variable = mi_scores_df.loc[mi_scores_df['Mutual_Info_Score'].idxmin()]\n",
    "print(\"Question 3: Variable with the lowest mutual information score:\", lowest_mi_variable['Feature'])\n",
    "\n",
    "# Question 4: Logistic regression model\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "model = LogisticRegression(solver='liblinear', C=10, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Question 4: Accuracy on the validation dataset:\", round(accuracy, 2))\n",
    "\n",
    "# Question 5: Feature elimination\n",
    "original_accuracy = accuracy\n",
    "feature_differences = []\n",
    "\n",
    "for feature in categorical_features:\n",
    "    reduced_features = [f for f in categorical_features if f != feature]\n",
    "    X_train_reduced = X_train[:, [i for i, f in enumerate(categorical_features) if f != feature]]\n",
    "    X_val_reduced = X_val[:, [i for i, f in enumerate(categorical_features) if f != feature]]\n",
    "    model.fit(X_train_reduced, y_train)\n",
    "    y_pred_reduced = model.predict(X_val_reduced)\n",
    "    reduced_accuracy = accuracy_score(y_val, y_pred_reduced)\n",
    "    feature_differences.append((feature, original_accuracy - reduced_accuracy))\n",
    "\n",
    "min_difference_feature = min(feature_differences, key=lambda x: x[1])\n",
    "print(\"Question 5: Feature with the smallest difference:\", min_difference_feature[0])\n",
    "\n",
    "# Question 6: Ridge regression with logarithmic transformation\n",
    "X = data.drop(columns=['price'])\n",
    "y = np.log(data['price'])\n",
    "X_encoded = encoder.transform(X[categorical_features])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "alphas = [0, 0.01, 0.1, 1, 10]\n",
    "best_rmse = float('inf')\n",
    "best_alpha = None\n",
    "\n",
    "for alpha in alphas:\n",
    "    ridge_model = Ridge(alpha=alpha, solver='sag', random_state=42)\n",
    "    ridge_model.fit(X_train, y_train)\n",
    "    y_pred = ridge_model.predict(X_val)\n",
    "    rmse = sqrt(mean_squared_error(y_val, y_pred))\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_alpha = alpha\n",
    "\n",
    "print(\"Question 6: Best alpha for Ridge regression:\", best_alpha)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0ff25b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
